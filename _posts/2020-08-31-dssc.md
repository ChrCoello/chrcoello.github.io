# Load forecasting at the secondary substation level

At [Elvia](https://www.elvia.no/), Norway's biggest distribution operators system in Norway, we had the chance to host our first iteration of what we called a Data Science Summer Camp. Four students were gather from the 15th of June to the 15th of August to work as a group (within the limits authorised by the health authorities) on a topic. [Gard Støe](https://www.linkedin.com/in/gardstoe/), at the origin of this initiative, and [myself](https://www.linkedin.com/in/chrcoello/) decided to propose four use cases of interest for the company, and the students picked up one to work on in the next 8 weeks.

Here's the table of contents:

1. TOC
{:toc}

## Use-Case

The students decided to look more in detail how could we forecast the load at the secondary substation level. Elvia AS has roughly 25'000 secondary substations in its grid. One substation contains one or more transformers (TFs) that brings voltage down from 11/22 kV to 240/400V [^2]. From these transformers, the electricity goes directly to the end users. As depicted in *Figure 1*, the electricity (or load) consumption of the end users connected to each TF will be the main driver of the electricity load that transits through the transformer.  
This load is what we are interested in forecasting. Several potential short- and long-term use cases can be interested in such forecast : 
 - preventing overload of the transformer
 - steering batteries installed on low-voltage grid
 - etc...  

In our case, we were interested in showing the technical feasibility of forecasting load at almost the finest granularity of an electricity grid network. By experience, we know that forecasting country level load is easier that forecasting end user level load, and therefore wanted to tackle the *hardest* use case for a DSO.

<img src="/images/2020-08-31-dssc/forecast_substation.svg" width="800" class="center" alt="Forecast substation">

*Figure.1 Schematic of the structure of the low voltage grid in Elvia. The timeseries represent the aggregated load over all the end users in one TF over a two-year period.*

Forecasting the load of one TF is of course interesting. But we identified very early the need to address all TF, not just one. As a consequence, we understood very early that having 25'000 models in production was something we didn't want to have. In addition, as shown in *Figure 1* with `tr1` and `tr2`, substations with similar type of end user present similar load. With both this in mind, we thought as very logical to reduce the amount of models.  
Clustering similar substations based on either existing labels or purely based on data was then added before  forecasting so that we need K models (where K is the number of models) instead of N models (where N is the number of substations). A schematic of the workflow we had set up for this summer camp can be seen in *Figure 2* : pre-processing, clustering and forecasting.

<img src="/images/2020-08-31-dssc/forecast_substation_workflow_woOpt.svg" width="800" class="center" alt="Schematic workflow">

*Figure.2 Schematic and modules addressed during the summer camp*

## Pre-processing

Very briefly described the pre-processing done to each timeserie *tr(t)*. First we remove the values that where zero (due to loss of temporary loss of electricity). The data was then z-transform : 
$$
z_{tr}(t) = \frac{tr(t) - \mu_{tr}}{\sigma_{tr}} 
$$ 
where $\mu_{tr}$ and $\sigma_{tr}$ are respectively the mean and the standard deviation measured during the whole historical period. Finally, we created for each z-transformed substation load a weekly average by averaging every instance of time and day of the week in the historical period. For example, the first point of this weekly average corresponds to Monday at 01:00: this point was obtained by averaging all Mondays at 01:00 found in the historical period.  

In addition to this data pre-processing, we assigned a **sector**-label to each substation. This substation sector-label is based on the sector (type) of the end-users connected to it that has the highest annual consumption. Let's look at one example:   

| Amount|End-user type|Annual consumption (kWh)|  
|----------------------------|--------------------------|--------------------------|  
| 2    | Other industry/building | 392762 |      
| 1    | Other | 1230 | 
| 6    | Household | 47163 |  

In this example, we that the substation has 9 end-users connected to it with *Household* being the type with most end-users. But we also see that the annual consumption for the label *Other industry/building* is higher than for *Household*, and there fore this substation will get the sector-label *Other industry/building* attached to it.  
With this method, we obtained 22 different sector-label substation in the whole dataset. To make the analysis easier, we limited our study to only the three sector-labels with most substation: *household* (4134), *cabin* (379) and *industry* (229).

## Clustering

Two main clustering approaches were used/tested: 
 - label-driven clustering: each substation is clustered solely based on the label assigned (based on end user category, see previous chapter)
 - data-driven clustering: each substation is clustered solely based on the consumption pattern

Both methods allow to reduce the input data space from `N` to `K` and to create clusters of similar consumption patterns. Assessing clusters is dependant on how one uses these clusters. Depending on the use, we might be interested more in one of these cluster properties: compactness, differentiability, substantiality and stability [^1]. In our case, we are be interested in validating the clusters in conjunction with the forecasts results, more about this in the last part of the blog post.  
A bit more details about assumptions underlying label-driven and data-driven clustering. 

### Label-driven clustering

This is the easiest to understand: each substation is assigned to its cluster based on the label assigned during the pre-processing step. Because of how the assignment of the label was done, we expect that the consumption pattern will be similar within each cluster. 
The advantage of this method is that it is easy to implement, computationally inexpensive, and you don't have to define a temporal period where you define a consumption pattern (daily, weekly, monthly, yearly, etc...) prior to the clustering.  
But the main disadvantage is that you are dependent at all "household" label have the same consumption pattern. For several reasons (concrete example: a nursery that is registered as household), this is not the case nas therefore the clusters obtained by this method could be less compact. In addition, this method limits the number of cluster `K` to the existing number of labels.

<img src="/images/2020-08-31-dssc/label_based_cluster.png" width="800" class="center" alt="Label based clusters">  
*Figure 1. Label-based clustering for label house (top), cabin (middle) and industry (bottom). Blue lines represent the weekly average of each individual substation and the black lines are the cluster centroid.* 

### Data-driven clustering

In the purely data-driven cluster, the algorithm (K-Means, K-Shape, Hierarchical) decides about the members of the clusters. I'll let the reader Google the name of these algorithm and read more about the theory about how we obtain clusters that have smallest intra-cluster distance and the largest inter-cluster distance.  
I would emphasize more about the choices made during this summer camp. First, we decided to standardize the z-transformed load timeseries by generating a weekly average of the whole historical period accessible for each TF. We then obtained a 168 data points per TF, the first point of this new representation of the data being for example the average of all Mondays at 01:00 that exist in the whole historical period.  
The choice of using week instead of day or month is rather related to the consumption patterns in households, industries and even more cabins.

**TO DO**
*Figure 2. Data-based clustering and distribution of the labels in each data-driven clusters.* 

The advantage of these data-driven methods are that the number of cluster is a hyper-parameter that the user can set prior to running the algorithm. Interesting to see that choosing 3 clusters is what the elbow method ([REF]), and that using 3 clusters generates very similar clusters to the one obtained in the label-driven clusters (*Figure 2*).


The clustering process is useful to reduce the amount of forecasting models we need to train from `N` to `K`. Very early, the tradeoff (*Figure 3*) between number and models and accuracy was identified by thinking about the extreme cases:  
 - `K=N`: one model per substation, too many models but best forecasting accuracy
 - `K=1`: one model for all substations, ideal scenario in term of number of models, but loss in forecasting accuracy

<img src="/images/2020-08-31-dssc/tradeoff.png" width="400" class="center" alt="Tradeoff"> 

*Figure 3. Tradeoff between the number of forecasting models trained and the accuracy of the forecast*



  

## Forecasting

The ingredients necessary for training a forecasting model were discussed early in the summer camp:
 1. what models to test 
 2. what features to investigate
 3. what cases should we run through

The problem we are trying to solve here is a regression problem, and as Bishop defines in his [seminal book](https://cds.cern.ch/record/998831): 

> The goal of regression is to predict the value of one or more continuous *target* variables *t* given the value of a *D*-dimensional vector **x** of *input* variables (or features). Given a training data set comprising *N* observations {**x**n}, where *n* = 1, . . . , *N*, together with corresponding target values {**t**n}, the goal is to predict the value of *t* for a new value of **x**. In the simplest approach, this can be done by directly constructing an appropriate function *y*(**x**) whose values for new inputs **x** constitute the
predictions for the corresponding values of *t*.  

The function *y* is an approximation (model) of the process that generates the target *t*.


### Models
The recommendation made to the students were as follows: test some (to a lot) of models using the default hyperparameters and the same set of features (what I call *light test*). Choose between the ones that seem to be responding well, and study more in depth these 3-4 models of interest.  
We deliberately didn't test the [classical TS forecasting models](https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/) like ARIMA, but focused on ML models. The students were active and looked at successful Kaggle models, used Google a lot and ended up looking and *light testing* the following models: Random Forest Regressor, Gradient Boosting Regressor, Support Vector Machine, Ridge regression, Lasso regression, Facebook Prophet, Nbeats, Sequential, CatBoost Regressor, LightGBM Regressor.  
Out of this mountain of models, four models were selected for deeper look:
 - Random Forest Regressor, 
 - Gradient Boosting Regressor,
 - CatBoost Regressor,
 - Facebook Prophet

### Features
As one can see in the `tr1` and `tr2` of Figure 1, Norwegian consumption variability is negatively correlated with the outside temperature. We also expect the consumption to be variable in relation the hour of the day, the day of the week and the local holidays. More interesting, we know that historical load is also an interesting predictor for future load. After some iterations, we settle in using the load 7 days, 4 days and 3 days in the past as features. Finally, we added a sort of *normal* curve, weekly average of the historical data. In fine, these are the features we used three continuous features: 
 -  Load for 7, 4 og 3-days in the past
 -  Weekly average of the historical load
 -  Temperature (historical forecasts)
and four categorical features:
 -  Hour ∈ [0, 23]
 -  Day of the week ∈ [0, 6]
 -  Month ∈ [1, 12]
 -  Holidays ∈ [True, False]
 
### Cases
For us, it was interesting to test the models in different cases. Four cases were thought to be implemented
 1. Case 1: predicting individual substations with one model per substation
 2. Case 2: predicting individual substations with one model per cluster
 3. Case 3: predicting individual substations with one model for all substations  
   
By studying these three cases, we ought to show the degradation of the accuracy metric as we hypothesized that the accuracy metric (we choose *MAPE*, mean percentage absolute error) is going to degrade as follows:
$$
    MAPE_{case1} < MAPE_{case2} < MAPE_{case3}
$$ 
where the MAPE (%) is expressed as : 
$$
MAPE = 100 * \frac{\sum_{t=1}^{67}\widehat{tr(t)}-tr(t)}{\sum_{t=1}^{67} tr(t)}
$$ 
where $\widehat{tr(t)}$ is the model prediction at time *t* and $tr_t$ is the true value at time $t$.

### Results

All the models were trained using historical data spanning the period from 1 June 2018 to 31 January 2020. Cross-validation was done for the four models to select the best set of hyperparameters. We then tested the models with using the load from 1st Feb 2020 to 15th March 2020.  
We decided to focus on short-horizon forecast (couple of days ahead). As we have freely accessible hourly weather forecast 67 hours in the future from the [Norwegian meteorological institute](https://met.no), we tested the models for 15 forecast horizons (67 hours), as 67 hours x 15 covers the test period.  
To make it easy to read, we chose two substations of each sector studied (*household*, *cabin* and *industry*).  

#### Case 1. Predicting using one model per NS

|| House 1| House 2|Cabin 1|Cabin 2| Industry 1| Industry 2|
|----------------------------|--------------------------|--------------------------|---------------------------|----------------------------|--------------------------|--------------------------|
|                            | Mean \ Std |Mean \ Std |Mean \ Std| Mean \ Std | Mean \ Std |  Mean \ Std |
| Random Forest              | {{rf_house1_MAPE_mean}}  \  {{rf_house1_MAPE_std}} | {{rf_house2_MAPE_mean}} \ {{rf_house2_MAPE_std}} |  {{rf_cabin1_MAPE_mean}} \ {{rf_cabin1_MAPE_std}}| {{rf_cabin2_MAPE_mean}} \ {{rf_cabin2_MAPE_std}}| {{rf_industry1_MAPE_mean}} \ {{rf_industry1_MAPE_std}} | {{rf_industry2_MAPE_mean}} \ {{rf_industry2_MAPE_std}} |
| Gradient Boosting regressor| {{gbr_house1_MAPE_mean}}  \  {{gbr_house1_MAPE_std}} | {{gbr_house2_MAPE_mean}} \ {{gbr_house2_MAPE_std}} |{{gbr_cabin1_MAPE_mean}} \ {{gbr_cabin1_MAPE_std}}|{{gbr_cabin2_MAPE_mean}} \ {{gbr_cabin2_MAPE_mean}}| {{gbr_industry1_MAPE_mean}} \ {{gbr_industry1_MAPE_std}}| {{gbr_industry2_MAPE_mean}} \ {{gbr_industry2_MAPE_std}} |
| CatBoost Regressor         | {{cb_house1_MAPE_mean}}  \  {{cb_house1_MAPE_std}} | {{cb_house2_MAPE_mean}} \ {{cb_house2_MAPE_std}} |  {{cb_cabin1_MAPE_mean}} \ {{cb_cabin1_MAPE_std}}| {{cb_cabin2_MAPE_mean}} \ {{cb_cabin2_MAPE_std}}| {{cb_industry1_MAPE_mean}} \ {{cb_industry1_MAPE_std}} | {{cb_industry2_MAPE_mean}} \ {{cb_industry2_MAPE_std}} | | 
| Facebook Prophet            | {{fb_house1_MAPE_mean}}  \  {{fb_house1_MAPE_std}} | {{fb_house2_MAPE_mean}} \ {{fb_house2_MAPE_std}} |  {{fb_cabin1_MAPE_mean}} \ {{fb_cabin1_MAPE_std}}| {{fb_cabin2_MAPE_mean}} \ {{fb_cabin2_MAPE_std}}| {{fb_industry1_MAPE_mean}} \ {{fb_industry1_MAPE_std}} | {{fb_industry2_MAPE_mean}} \ {{fb_industry2_MAPE_std}} | 


#### Case 2. Predicting using one model per cluster

|| House 1| House 2|Cabin 1|Cabin 2| Industry 1| Industry 2|
|----------------------------|--------------------------|--------------------------|---------------------------|----------------------------|--------------------------|--------------------------|



## Discussion
This was our first deep dive into forecasting problems at Elvia. We have now an idea about the possibilities, the possible accuracy of the short-horizon forecasts we could provide to our domain experts sitting at the control centre. The students have done a tremendous job into setting up what will be our reference pipeline to quickly customized future forecasting problems. 
The normal continuation of this project would be to optimise the number of cluster and the accuracy of the models at the same time to find a sweet spot where both K and accuracy are optimize simultaneously.  
<img src="/images/2020-08-31-dssc/forecast_substation_workflow.svg" width="400" class="center" alt="Tradeoff">


One step further, the problem of learning in deep learning (DL) is cast as a search or optimization problem to navigate the space of possible sets of weights the model may use in order to make good enough predictions. This optimization is coded in the loss function of the DL framework. So we might think that with an appropriate DL architecture and loss function, one could simplify the problem to one DL model. This is idea is attractive and we are taking this project further together with the [ML group](https://machine-learning.uit.no/) in Tromsø to investigate this possibility.
<img src="/images/2020-08-31-dssc/forecast_substation_workflow_DL.svg" width="400" class="center" alt="Tradeoff">


## Footnotes

[^2]: because more than 95% of substation contain only one TF, we switch between substation and transformer during this blog post
[^1]: Stian Norheim, **Clustering of AMS-data**, Master’s thesis in Energy and Environment, NTNU. June 2020.

