# Load forecasting at the secondary substation level

At [Elvia](https://www.elvia.no/), Norway's biggest distribution operators system in Norway, we had the chance to host our first iteration of what we called a Data Science Summer Camp. Four students were gather from the 15th of June to the 15th of August to work as a group (within the limits authorised by the health authorities) on a topic. [Gard Støe](https://www.linkedin.com/in/gardstoe/), at the origin of this initiative, and [myself](https://www.linkedin.com/in/chrcoello/) decided to propose four use cases of interest for the company, and the students picked up one to work on in the next 8 weeks.

Here's the table of contents:

1. TOC
{:toc}

## Use-Case

The students decided to look more in detail how could we forecast the load at the secondary substation level. Elvia AS has roughly 25'000 secondary substations in its grid. One substation contains one or more transformers (TFs) that brings voltage down from 11/22 kV to 240/400V [^2]. From these transformers, the electricity goes directly to the end users. As depicted in *Figure 1*, the electricity (or load) consumption of the end users connected to each TF will be the main driver of the electricity load that transits through the transformer.  
This load is what we are interested in forecasting. Several potential short- and long-term use cases can be interested in such forecast : 
 - preventing overload of the transformer
 - steering batteries installed on low-voltage grid
 - etc...  

In our case, we were interested in showing the technical feasibility of forecasting load at almost the finest granularity of an electricity grid network. By experience, we know that forecasting country level load is easier that forecasting end user level load, and therefore wanted to tackle the *hardest* use case for a DSO.

<img src="/images/2020-08-31-dssc/forecast_substation.svg" width="800" class="center" alt="Forecast substation">

*Figure.1 Schematic of the structure of the low voltage grid in Elvia*

Forecasting the load of one TF is of course interesting. But we identified very early the need to address all TF, not just one. As a consequence, we understood very early that having 25'000 models in production was something we didn't want to have. In addition, as shown in *Figure 1* with `tr1` and `tr2`, substations with similar type of end user present similar load. With both this in mind, we thought as very logical to reduce the amount of models.  
Clustering similar substations based on either existing labels or purely based on data was then added before  forecasting so that we need K models (where K is the number of models) instead of N models (where N is the number of substations). A schematic of the workflow we had set up for this summer camp can be seen in *Figure 2* : pre-processing, clustering and forecasting.

<img src="/images/2020-08-31-dssc/forecast_substation_workflow_woOpt.svg" width="800" class="center" alt="Schematic workflow">

*Figure.2 Schematic and modules addressed during the summer camp*

## Pre-processing

**TO DO**

Key ideas: 
 - removing zero values, 
 - z-transform, 
 - weekly average, 
 - labels per nettstatjon


**TO DO**

## Clustering

Two main clustering approaches were used/tested: 
 - label-driven clustering: each substation is clustered solely based on the label assigned (based on end user category, see previous chapter)
 - data-driven clustering: each substation is clustered solely based on the consumption pattern

Both methods allow to reduce the input data space from `N` to `K` and to create clusters of similar consumption patterns. Assessing clusters is dependant on how one uses these clusters. Depending on the use, we might be interested more in one of these cluster properties: compactness, differentiability, substantiality and stability [^1]. In our case, we are be interested in validating the clusters in conjunction with the forecasts results, more about this in the last part of the blog post.  
A bit more details about assumptions underlying label-driven and data-driven clustering. 

### Label-driven clustering

This is the easiest to understand: each substation has a label assigned to it that is either household, cabin or industry. We then expect that the consumption pattern will be similar within one cluster.  
The advantage of this method is that it is easy to implement, computationally inexpensive, and you don't have to define a temporal period where you define a consumption pattern (daily, weekly, monthly, yearly, etc...) prior to the clustering.  
But the main disadvantage is that you are dependent at all "household" label have the same consumption pattern. For several reasons (concrete example: a nursery that is registered as household), this is not the case nas therefore the clusters obtained by this method could be less compact. In addition, this method limits the number of cluster `K` to the existing number of labels.

<img src="/images/2020-08-31-dssc/label_based_cluster.png" width="800" class="center" alt="Label based clusters">  
*Figure 1. Label-based clustering for label house (top), cabin (middle) and industry (bottom). Blue lines represent the weekly average of each individual substation and the black lines are the cluster centroid.* 

### Data-driven clustering

In the purely data-driven cluster, the algorithm (K-Means, K-Shape, Hierarchical) decides about the members of the clusters. I'll let the reader Google the name of these algorithm and read more about the theory about how we obtain clusters that have smallest intra-cluster distance and the largest inter-cluster distance.  
I would emphasize more about the choices made during this summer camp. First, we decided to standardize the z-transformed load timeseries by generating a weekly average of the whole historical period accessible for each TF. We then obtained a 168 data points per TF, the first point of this new representation of the data being for example the average of all Mondays at 01:00 that exist in the whole historical period.  
The choice of using week instead of day or month is rather related to the consumption patterns in households, industries and even more cabins.

**TO DO**
*Figure 2. Data-based clustering and distribution of the labels in each data-driven clusters.* 

The advantage of these data-driven methods are that the number of cluster is a hyper-parameter that the user can set prior to running the algorithm. Interesting to see that choosing 3 clusters is what the elbow method ([REF]), and that using 3 clusters generates very similar clusters to the one obtained in the label-driven clusters (*Figure 2*).


The clustering process is useful to reduce the amount of forecasting models we need to train from `N` to `K`. Very early, the tradeoff (*Figure 3*) between number and models and accuracy was identified by thinking about the extreme cases:  
 - `K=N`: one model per substation, too many models but best forecasting accuracy
 - `K=1`: one model for all substations, ideal scenario in term of number of models, but loss in forecasting accuracy

<img src="/images/2020-08-31-dssc/tradeoff.png" width="400" class="center" alt="Tradeoff"> 

*Figure 3. Tradeoff between the number of forecasting models trained and the accuracy of the forecast*

  

## Forecasting

The ingredients necessary for training a forecasting model were discussed early in the summer camp:
 1. what models to test 
 2. what features to investigate
 3. what cases should we run through

The problem we are trying to solve here is a regression problem, and as Bishop defines in his [seminal book](https://cds.cern.ch/record/998831): 

    The goal of regression is to predict the value of one or more continuous *target* variables *t* given the value of a *D*-dimensional vector **x** of *input* variables (or features). Given a training data set comprising *N*observations {**x**n}, where *n* = 1, . . . , *N*, together with corresponding target values {**t**n}, the goal is to predict the value of *t* for a new value of **x**. In the simplest approach, this can be done by directly constructing an appropriate function *y*(**x**) whose values for new inputs **x** constitute the
    predictions for the corresponding values of *t*.


### Models
The recommendation made to the students were as follows: test some (to a lot) of models using the default hyperparameters and the same set of features. Choose between the ones that seem to be responding well, and study more in depth these 3-4 models of interest.  
We deliberately didn't test the [classical TS forecasting models](https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/) like ARIMA, but focused on ML models. The students were active and looked at successful Kaggle models, Google a lot and ended up testing the following models: Random





Key points to add
*challenges of real world dirty data*  
*The ocean of possibilities, how to choose a model*  
*Results with three different approaches*  

---

## Extra

Here's a list:

- item 1
- item 2

And a numbered list:

1. item 1
1. item 2


> This is a quotation

{% include alert.html text="You can include alert boxes" %}

...and...

{% include info.html text="You can include info boxes" %}


![](/images/logo.png "fast.ai's logo")


General preformatted text:

    # Do a thing
    do_thing()

Python code and output:

```python
# Prints '2'
print(1+1)
```

    2


| Column 1 | Column 2 |
|-|-|
| A thing | Another thing |

## Footnotes

[^2]: because more than 95% of substation contain only one TF, we switch between substation and transformer during this blog post
[^1]: Stian Norheim, **Clustering of AMS-data**, Master’s thesis in Energy and Environment, NTNU. June 2020.

