# Load forecasting at the secondary substation level

At [Elvia](https://www.elvia.no/), Norway's biggest distribution operators system in Norway, we had the chance to host our first iteration of what we called a Data Science Summer Camp. Four students were gather from the 15th of June to the 15th of August to work as a group (within the limits authorised by the health authorities) on a topic. [Gard Støe](https://www.linkedin.com/in/gardstoe/), at the origin of this initiative, and [myself](https://www.linkedin.com/in/chrcoello/) decided to propose four use cases of interest for the company, and the students picked up one to work on in the next 8 weeks.

Here's the table of contents:

1. TOC
{:toc}

## Use-Case

The students decided to look more in detail how could we forecast the load at the secondary substation level. Elvia AS has roughly 25'000 secondary substations in its grid. The substations contain one or more transformers (TFs) that brings voltage down from 11/22 kV to 240/400V. From these transformers, the electricity goes directly to the end users. As depicted in *Figure 1*, the electricity (or load) consumption of the end users connected to each TF will be the main driver of the electricity load that transits through the transformer.  
This load is what we are interested in forecasting. Several potential short- and long-term use cases can be interested in such forecast : 
 - preventing overload of the transformer
 - steering batteries installed on low-voltage grid
 - etc...  

In our case, we were interested in showing the technical feasibility of forecasting load at almost the finest granularity of an electricity grid network. By experience, we know that forecasting country level load is easier that forecasting end user level load, and therefore wanted to tackle the *hardest* use case for a DSO.

<img src="/images/2020-08-31-dssc/forecast_substation.svg" width="800" class="center" alt="Forecast substation">

*Figure.1 Schematic of the structure of the low voltage grid in Elvia*

Forecasting the load of one TF is of course interesting. But we identified very early the need to address all TF, not just one. As a consequence, we understood very early that having 25'000 models in production was something we didn't want to have. In addition, as shown in *Figure 1* with `tr1` and `tr2`, substations with similar type of end user present similar load. With both this in mind, we thought as very logical to reduce the amount of models.  
Clustering similar substations based on either existing labels or purely based on data was then added before  forecasting so that we need K models (where K is the number of models) instead of N models (where N is the number of substations). A schematic of the workflow we had set up for this summer camp can be seen in *Figure 2* : pre-processing, clustering and forecasting.

<img src="/images/2020-08-31-dssc/forecast_substation_workflow_woOpt.svg" width="800" class="center" alt="Schematic workflow">

*Figure.2 Schematic and modules addressed during the summer camp*

## Pre-processing

**TO DO**

Key ideas: 
 - removing zero values, 
 - z-transform, 
 - weekly average, 
 - labels per nettstatjon


**TO DO**

## Clustering

Two main clustering approaches were used/tested: 
 - label-driven clustering: each substation is clustered solely based on the label assigned (based on end user category, see previous chapter)
 - data-driven clustering: each substation is clustered solely based on the consumption pattern

Both methods allow to reduce the input data space from `N` to `K` and to create clusters of similar consumption patterns. Assessing clusters is dependant on how one uses these clusters: we can be interested in compactness, differentiability, substantiality and stability [^1]. 
But each of these methods have own assumptions that will describe here. 

### Label-driven clustering

This is the easiest to understand: each substation has a label assigned to it that is either household, cabin or industry. We then expect that the consumption pattern will be similar within one cluster.  
The advantage of this method is that it is easy to implement, computationally inexpensive, and you don't have to define a temporal period where you define a consumption pattern (daily, weekly, monthly, yearly, etc...) prior to the clustering.  
But the main disadvantage is that you are dependent at all "household" label have the same consumption pattern. For several reasons (concrete example: a nursery that is registered as household), this is not the case nas therefore the clusters obtained by this method could be less compact. In addition, this method limits the number of cluster `K` to the existing number of labels.

<img src="/images/2020-08-31-dssc/label_based_cluster.png" width="800" class="center" alt="Label based clusters">  
*Figure 1. Label-based clustering for label house (top), cabin (middle) and industry (bottom). Blue lines represent the weekly average of each individual substation and the black lines are the cluster centroid.* 

### Data-driven clustering



 - standardizing every timeserie by reduce the whole period into an average week  (z-transform followed by average per week) N points-> 168 points
 - using this lower space representation to cluster between substation
 - assessing of cluster is dependant on how one uses this clusters -> Compactness, Differentiable, Substantial, Stable 
 - At the end we have K number of clusters that show similar weekly load patterns
 - How to choose K -> elbow method ? 
The clustering process is herea tool to reduce the input data space from `N` to `K`.   

Figures:  


 - three data-driven clusters and repartition of each label in these clusters
 - six data-driven clusters and repartition of each label in these clusters
 - elbow curve ?
  


## Forecasting

Key points to add
*challenges of real world dirty data*  
*The ocean of possibilities, how to choose a model*  
*Results with three different approaches*  

---

## Extra

Here's a list:

- item 1
- item 2

And a numbered list:

1. item 1
1. item 2


> This is a quotation

{% include alert.html text="You can include alert boxes" %}

...and...

{% include info.html text="You can include info boxes" %}


![](/images/logo.png "fast.ai's logo")


General preformatted text:

    # Do a thing
    do_thing()

Python code and output:

```python
# Prints '2'
print(1+1)
```

    2


| Column 1 | Column 2 |
|-|-|
| A thing | Another thing |

## Footnotes

[^1]: Stian Norheim, **Clustering of AMS-data**, Master’s thesis in Energy and Environment, NTNU. June 2020.

